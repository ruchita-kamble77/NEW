import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import seaborn as sns
import matplotlib.pyplot as plt

# Load dataset
df = pd.read_csv("Mall_Customers.csv")

# Select features
X = df[['Annual Income (k$)', 'Spending Score (1-100)']]

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply KMeans with chosen clusters (e.g., k=5)
kmeans = KMeans(n_clusters=5, random_state=42)
clusters = kmeans.fit_predict(X_scaled)

# Add cluster labels to dataframe
df['Cluster'] = clusters

# Visualize clusters
plt.figure(figsize=(10,6))
sns.scatterplot(data=df, x='Annual Income (k$)', y='Spending Score (1-100)', hue='Cluster', palette='Set2', s=100)
plt.title('Customer Segmentation by K-Means Clustering')
plt.show()
---------------------------------------------------------------------------------------

from pyspark.sql import SparkSession

# Initialize Spark session
spark = SparkSession.builder.appName("HighValueTransactions").getOrCreate()

# Load JSON data
df = spark.read.json("transactions.json")

# Filter transactions with Amount > 10,000 INR
high_value_txn = df.filter(df['Amount'] > 10000)

# Select relevant columns (assuming customer and product info columns)
high_value_txn.select('CustomerID', 'ProductID', 'Amount').show(truncate=False)

# Stop Spark session after use (optional)
spark.stop()

